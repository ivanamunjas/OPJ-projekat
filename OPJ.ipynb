{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_functional = False # Whether to merge Functional comments into one class\n",
    "n_gram = 1  # here we chose [1, 2, 3] for [unigrams, bigrams, trigrams]\n",
    "l_penalty = 'l2' # we can choose between l1 and l2 for logistic regression and SVM\n",
    "param_min_df = 1\n",
    "param_max_df = 1.0\n",
    "use_stemmer = True\n",
    "use_tf_idf = False\n",
    "use_idf = False\n",
    "remove_special_chars = True\n",
    "use_lowercase = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "t_start = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_common_df(id_):\n",
    "    try:\n",
    "        cols = ['NaturalLanguageID', 'ProgrammingLanguageName', 'RepoID', 'SourceID', 'CommentID', 'comment', 'label']\n",
    "        df = pd.read_csv('Data\\\\Common\\\\OutDataCommon{}.txt'.format(id_), sep='\\t', lineterminator='\\r', header=None)\n",
    "        df.columns = cols\n",
    "        df = df.drop(['NaturalLanguageID', 'ProgrammingLanguageName', 'RepoID', 'SourceID', 'CommentID'],axis=1)\n",
    "        return df\n",
    "    except:\n",
    "        with open('Data\\\\Common\\OutDataCommon{}.txt'.format(id_), \"r\", encoding=\"utf-8\",  newline=\"\\r\\n\") as source:\n",
    "            for line in source:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                part = line.split(\"\\t\")\n",
    "                if len(part) != 7:\n",
    "                    print('POPRAVITI .TXT')\n",
    "                    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = create_common_df(1)\n",
    "df2 = create_common_df(2)\n",
    "df3 = create_common_df(3)\n",
    "df4 = create_common_df(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = df1.merge(df2, how='left', on='comment', suffixes=('_1', '_2')).merge(df3, how='left', on='comment').merge(df4, how='left', on='comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = merged.columns.values\n",
    "cols[3] = 'label_3'\n",
    "cols[4] = 'label_4'\n",
    "merged.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop_duplicates(subset =\"comment\", keep = False, inplace = True)\n",
    "merged = merged.dropna()\n",
    "merged = merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = np.zeros((merged.shape[0],6))\n",
    "\n",
    "for i in range(merged.shape[0]):\n",
    "    if merged.loc[i]['label_1'] == merged.loc[i]['label_2']:\n",
    "        hits[i][0] += 1\n",
    "    if merged.loc[i]['label_1'] == merged.loc[i]['label_3']:\n",
    "        hits[i][1] += 1\n",
    "    if merged.loc[i]['label_1'] == merged.loc[i]['label_4']:\n",
    "        hits[i][2] += 1\n",
    "    if merged.loc[i]['label_2'] == merged.loc[i]['label_3']:\n",
    "        hits[i][3] += 1\n",
    "    if merged.loc[i]['label_2'] == merged.loc[i]['label_4']:\n",
    "        hits[i][4] += 1\n",
    "    if merged.loc[i]['label_3'] == merged.loc[i]['label_4']:\n",
    "        hits[i][5] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_same = 0\n",
    "three_same_one_diff = 0\n",
    "two_same_two_diff = 0\n",
    "two_same_one_diff_one_diff = 0\n",
    "all_diff = 0\n",
    "\n",
    "for i in range(hits.shape[0]):\n",
    "    if hits[i].sum() == 6:\n",
    "        all_same += 1 \n",
    "    if hits[i].sum() == 3:\n",
    "        three_same_one_diff += 1\n",
    "    if hits[i].sum() == 2:\n",
    "        two_same_two_diff += 1\n",
    "        \n",
    "    if hits[i].sum() == 1:\n",
    "        two_same_one_diff_one_diff += 1\n",
    "    if hits[i].sum() == 0:\n",
    "        all_diff += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All same:  354\n",
      "Three same, one different:  95\n",
      "Two same, two different (same to one another):  12\n",
      "Two same, two different (different from one another):  14\n",
      "All different:  1\n",
      "Total comments:  476\n"
     ]
    }
   ],
   "source": [
    "print('All same: ', all_same)\n",
    "print('Three same, one different: ', three_same_one_diff)\n",
    "print('Two same, two different (same to one another): ', two_same_two_diff)\n",
    "print('Two same, two different (different from one another): ', two_same_one_diff_one_diff)\n",
    "print('All different: ', all_diff)\n",
    "print('Total comments: ', merged.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All same (%):  74\n",
      "Three same, one different (%):  20\n",
      "Two same, two different (same to one another) (%):  3\n",
      "Two same, two different (different from one another) (%):  3\n",
      "All different (%):  0\n"
     ]
    }
   ],
   "source": [
    "print('All same (%): ', round(all_same/merged.shape[0]*100))\n",
    "print('Three same, one different (%): ',  round(three_same_one_diff/merged.shape[0]*100))\n",
    "print('Two same, two different (same to one another) (%): ',  round(two_same_two_diff/merged.shape[0]*100))\n",
    "print('Two same, two different (different from one another) (%): ',  round(two_same_one_diff_one_diff/merged.shape[0]*100))\n",
    "print('All different (%): ',  round(all_diff/merged.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procenat podudarnosti izmedju Laze i Matije:  87.0\n",
      "Procenat podudarnosti izmedju Laze i Mateje:  93.0\n",
      "Procenat podudarnosti izmedju Laze i Munje:  83.0\n",
      "Procenat podudarnosti izmedju Matije i Mateje:  89.0\n",
      "Procenat podudarnosti izmedju Matije i Ivane:  78.0\n",
      "Procenat podudarnosti izmedju Mateje i Ivane:  83.0\n"
     ]
    }
   ],
   "source": [
    "print('Procenat podudarnosti izmedju Laze i Matije: ', round(hits[:,0].sum()/merged.shape[0]*100))\n",
    "print('Procenat podudarnosti izmedju Laze i Mateje: ', round(hits[:,1].sum()/merged.shape[0]*100))\n",
    "print('Procenat podudarnosti izmedju Laze i Munje: ', round(hits[:,2].sum()/merged.shape[0]*100))\n",
    "print('Procenat podudarnosti izmedju Matije i Mateje: ', round(hits[:,3].sum()/merged.shape[0]*100))\n",
    "print('Procenat podudarnosti izmedju Matije i Ivane: ', round(hits[:,4].sum()/merged.shape[0]*100))\n",
    "print('Procenat podudarnosti izmedju Mateje i Ivane: ', round(hits[:,5].sum()/merged.shape[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ucitavanje svih podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    for id_ in range(1,5):\n",
    "        try:\n",
    "            cols = ['NaturalLanguageID', 'ProgrammingLanguageName', 'RepoID', 'SourceID', 'CommentID', 'comment', 'label']\n",
    "            df = pd.read_csv('Data\\\\All data\\\\OutData{}.txt'.format(id_), sep='\\t', lineterminator='\\r', header=None)\n",
    "            df.columns = cols\n",
    "            if id_ == 1:\n",
    "                dfs = df\n",
    "            else:\n",
    "                dfs = pd.concat([dfs,df], ignore_index=True)\n",
    "        except:\n",
    "            with open('Data\\\\All data\\\\OutData{}.txt'.format(id_), \"r\", encoding=\"utf-8\",  newline=\"\\r\\n\") as source:\n",
    "                for line in source:\n",
    "                    line = line.replace(\"\\n\", \"\")\n",
    "                    part = line.split(\"\\t\")\n",
    "                    if len(part) != 7:\n",
    "                        print('POPRAVITI .TXT')\n",
    "                        print(part)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df, df_common], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6491, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalLanguageID</th>\n",
       "      <th>ProgrammingLanguageName</th>\n",
       "      <th>RepoID</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>CommentID</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR</td>\n",
       "      <td>Java</td>\n",
       "      <td>BILD-IT-Advanced-master</td>\n",
       "      <td>src\\grupniProjekat_02_03_2016\\SearchEngine.java</td>\n",
       "      <td>BILD-IT-Advanced-master/src\\grupniProjekat_02_...</td>\n",
       "      <td>Ispisujemo poruku da je drajver loadovan \\n</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>BILD-IT-Advanced-master</td>\n",
       "      <td>src\\grupniProjekat_02_03_2016\\SearchEngine.java</td>\n",
       "      <td>BILD-IT-Advanced-master/src\\grupniProjekat_02_...</td>\n",
       "      <td>Ispis država za uneseni kontinent \\n</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>BILD-IT-Advanced-master</td>\n",
       "      <td>src\\grupniProjekat_02_03_2016\\SearchEngine.java</td>\n",
       "      <td>BILD-IT-Advanced-master/src\\grupniProjekat_02_...</td>\n",
       "      <td>Slanje upute \\n</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>BILD-IT-Advanced-master</td>\n",
       "      <td>src\\grupniProjekat_02_03_2016\\SearchEngine.java</td>\n",
       "      <td>BILD-IT-Advanced-master/src\\grupniProjekat_02_...</td>\n",
       "      <td>Ispis gradova koji pocinju odreðenim slovom \\n</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>BILD-IT-Advanced-master</td>\n",
       "      <td>src\\grupniProjekat_02_03_2016\\SearchEngine.java</td>\n",
       "      <td>BILD-IT-Advanced-master/src\\grupniProjekat_02_...</td>\n",
       "      <td>Hvatalica grešaka \\n</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>Projekat-master</td>\n",
       "      <td>src\\contoller\\Controller.java</td>\n",
       "      <td>Projekat-master/src\\contoller\\Controller.java/69</td>\n",
       "      <td>Dodavanje OpenGeneralTourListener TuraGui-ju \\n</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>raspored-master</td>\n",
       "      <td>src\\org\\svetovid\\raspored\\cmd\\Main.java</td>\n",
       "      <td>raspored-master/src\\org\\svetovid\\raspored\\cmd\\...</td>\n",
       "      <td>Grupisanje \\n</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>\\nEN/SR</td>\n",
       "      <td>Java</td>\n",
       "      <td>raspored-master</td>\n",
       "      <td>src\\org\\svetovid\\raspored\\model\\Tip.java</td>\n",
       "      <td>raspored-master/src\\org\\svetovid\\raspored\\mode...</td>\n",
       "      <td>\\n * Copyright 2018 Ivan Pribela \\n * \\n * Li...</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>RAUM-master</td>\n",
       "      <td>funkcija.java</td>\n",
       "      <td>RAUM-master/funkcija.java/260</td>\n",
       "      <td>Ako posle unarnog operanda sledi \"(\", za podfu...</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>\\nSR</td>\n",
       "      <td>Java</td>\n",
       "      <td>SCStemmers-master</td>\n",
       "      <td>src\\weka\\core\\stemmers\\SerbianStemmer.java</td>\n",
       "      <td>SCStemmers-master/src\\weka\\core\\stemmers\\Serbi...</td>\n",
       "      <td>\\n * Dužina (u karakterima) najdužeg sufiksno...</td>\n",
       "      <td>Functional-Inline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6491 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NaturalLanguageID ProgrammingLanguageName                   RepoID  \\\n",
       "0                   SR                    Java  BILD-IT-Advanced-master   \n",
       "1                 \\nSR                    Java  BILD-IT-Advanced-master   \n",
       "2                 \\nSR                    Java  BILD-IT-Advanced-master   \n",
       "3                 \\nSR                    Java  BILD-IT-Advanced-master   \n",
       "4                 \\nSR                    Java  BILD-IT-Advanced-master   \n",
       "...                ...                     ...                      ...   \n",
       "6486              \\nSR                    Java          Projekat-master   \n",
       "6487              \\nSR                    Java          raspored-master   \n",
       "6488           \\nEN/SR                    Java          raspored-master   \n",
       "6489              \\nSR                    Java              RAUM-master   \n",
       "6490              \\nSR                    Java        SCStemmers-master   \n",
       "\n",
       "                                             SourceID  \\\n",
       "0     src\\grupniProjekat_02_03_2016\\SearchEngine.java   \n",
       "1     src\\grupniProjekat_02_03_2016\\SearchEngine.java   \n",
       "2     src\\grupniProjekat_02_03_2016\\SearchEngine.java   \n",
       "3     src\\grupniProjekat_02_03_2016\\SearchEngine.java   \n",
       "4     src\\grupniProjekat_02_03_2016\\SearchEngine.java   \n",
       "...                                               ...   \n",
       "6486                    src\\contoller\\Controller.java   \n",
       "6487          src\\org\\svetovid\\raspored\\cmd\\Main.java   \n",
       "6488         src\\org\\svetovid\\raspored\\model\\Tip.java   \n",
       "6489                                    funkcija.java   \n",
       "6490       src\\weka\\core\\stemmers\\SerbianStemmer.java   \n",
       "\n",
       "                                              CommentID  \\\n",
       "0     BILD-IT-Advanced-master/src\\grupniProjekat_02_...   \n",
       "1     BILD-IT-Advanced-master/src\\grupniProjekat_02_...   \n",
       "2     BILD-IT-Advanced-master/src\\grupniProjekat_02_...   \n",
       "3     BILD-IT-Advanced-master/src\\grupniProjekat_02_...   \n",
       "4     BILD-IT-Advanced-master/src\\grupniProjekat_02_...   \n",
       "...                                                 ...   \n",
       "6486   Projekat-master/src\\contoller\\Controller.java/69   \n",
       "6487  raspored-master/src\\org\\svetovid\\raspored\\cmd\\...   \n",
       "6488  raspored-master/src\\org\\svetovid\\raspored\\mode...   \n",
       "6489                      RAUM-master/funkcija.java/260   \n",
       "6490  SCStemmers-master/src\\weka\\core\\stemmers\\Serbi...   \n",
       "\n",
       "                                                comment              label  \n",
       "0          Ispisujemo poruku da je drajver loadovan \\n   Functional-Inline  \n",
       "1                 Ispis država za uneseni kontinent \\n   Functional-Inline  \n",
       "2                                      Slanje upute \\n   Functional-Inline  \n",
       "3       Ispis gradova koji pocinju odreðenim slovom \\n   Functional-Inline  \n",
       "4                                 Hvatalica grešaka \\n   Functional-Inline  \n",
       "...                                                 ...                ...  \n",
       "6486   Dodavanje OpenGeneralTourListener TuraGui-ju \\n   Functional-Inline  \n",
       "6487                                     Grupisanje \\n   Functional-Inline  \n",
       "6488   \\n * Copyright 2018 Ivan Pribela \\n * \\n * Li...            General  \n",
       "6489  Ako posle unarnog operanda sledi \"(\", za podfu...  Functional-Inline  \n",
       "6490   \\n * Dužina (u karakterima) najdužeg sufiksno...  Functional-Inline  \n",
       "\n",
       "[6491 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    if df['NaturalLanguageID'][i][0] == '\\n':\n",
    "        df['NaturalLanguageID'][i] = df['NaturalLanguageID'][i][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['NaturalLanguageID'] == 'UNDEF'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[df['NaturalLanguageID'] == 'UNDEF'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6387, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6387, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['NaturalLanguageID'] == 'EN/SR'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_duplicates = df.drop_duplicates(['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6387, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4773, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droped_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the case we want to use Functional for all comments\n",
    "\n",
    "if merge_functional:\n",
    "    for i in range(df.shape[0]):\n",
    "        df.loc[i]['label'] = re.sub('-Inline', '', df['label'][i])\n",
    "        df.loc[i]['label'] = re.sub('-Method', '', df['label'][i])\n",
    "        df.loc[i]['label'] = re.sub('-Module', '', df['label'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6387, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2180, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duplicated('comment', keep=False)].sort_values('comment').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalLanguageID</th>\n",
       "      <th>ProgrammingLanguageName</th>\n",
       "      <th>RepoID</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>CommentID</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [NaturalLanguageID, ProgrammingLanguageName, RepoID, SourceID, CommentID, comment, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droped_duplicates[droped_duplicates.index == 3676]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['comment'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df['comment'].str.contains('NON')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Functional-Inline    2804\n",
       "Functional-Method    1076\n",
       "Functional-Module     504\n",
       "Notice                155\n",
       "Code                  109\n",
       "General                69\n",
       "ToDo                   34\n",
       "IDE                    20\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 'Notice'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 'General'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ov specificne metode mozda izbaciti i ostaviti samo opstem a uscitavanje rditi sa kastovanjem s \\\\n '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.index == 2044]['comment'][2044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.comment.apply(lambda x: len(str(x)) < 6)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4733, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing all comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    # pretvaranje celog teksta u mala slova\n",
    "    if use_lowercase:\n",
    "        df.loc[i]['comment'] = df.loc[i]['comment'].lower()\n",
    "    # izbacivanje special character-a\n",
    "    if remove_special_chars:\n",
    "        df['comment'][i] = re.sub(r'\\W', ' ', df['comment'][i])\n",
    "        # izbacivanje new line oznake\n",
    "        df['comment'][i] = re.sub(r'\\b[n]\\b', '', df['comment'][i])\n",
    "        # zamena vise razmaka s jednim razmakom\n",
    "        df['comment'][i] = re.sub(r'\\s+', ' ', df['comment'][i], flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ispisujemo poruku da je drajver loadovan \n",
      " ispis država za uneseni kontinent \n",
      " slanje upute \n",
      " ispis gradova koji pocinju odreðenim slovom \n",
      " hvatalica grešaka \n",
      " konstruktor sa data fields \n",
      " guest button \n",
      " ok button za login admin \n",
      " zatvaranje pregleda racuna \n",
      " button za pregled racuna za datog korisnika \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(df['comment'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4733, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ispisujemo poruku da je drajver loadovan ',\n",
       "       ' ispis država za uneseni kontinent ', ' slanje upute ', ...,\n",
       "       ' grupisanje ',\n",
       "       'ako posle unarnog operanda sledi za podfunkciju uzimam sve sto je u zagradi ',\n",
       "       ' dužina u karakterima najdužeg sufiksnog pravila p i length in characters of the longest suffix rule i '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Functional-Inline    2771\n",
       "Functional-Method    1076\n",
       "Functional-Module     504\n",
       "Notice                151\n",
       "Code                  109\n",
       "General                69\n",
       "ToDo                   33\n",
       "IDE                    20\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Functional-Inline', 'Functional-Inline', 'Functional-Inline', ...,\n",
       "       'Functional-Inline', 'Functional-Inline', 'Functional-Inline'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['comment'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mateja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jovi', 'jesam', 'isx', 'u', 'sxkol', '.', 'marij', 'jesam', 'dobr', 'devoj', '.']\n",
      " jovi jesam isx u sxkol . marij jesam dobr devoj .\n"
     ]
    }
   ],
   "source": [
    "# Pokrenuti ovo za koriscenje stemmovanja\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import StemmerByNikola\n",
    "from StemmerByNikola import stem_str\n",
    "\n",
    "if use_stemmer:\n",
    "    stemmed_x = []\n",
    "    for doc in x:\n",
    "        stemmed_x.append(stem_str(doc))\n",
    "    \n",
    "    x = np.array(stemmed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deo gde se radi obicna vektorizacija bez TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', # lowercase=True, # Menjanjem ovoga testiramo lowercase uticaj\n",
    "                             ngram_range=(1, n_gram), # Podesavanjem ovoga testiramo bigramski i trigramski uticaj\n",
    "                             min_df=param_min_df, max_df=param_max_df) # Podesavanjem ova dva testiracemo uticaj frekvencijskog filtriranja\n",
    "\n",
    "vectorizer.fit(x)\n",
    "\n",
    "x = vectorizer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "if use_tf_idf:\n",
    "    tfidfconverter = TfidfTransformer(use_idf=use_idf)\n",
    "    x = tfidfconverter.fit_transform(x).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, random_state=151, shuffle=True)\n",
    "kf.get_n_splits(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    data = confusion_matrix(y_test, y_pred)\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.4)#for label size\n",
    "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt=\"d\", annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression L penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:\n",
      "Accuracy: 0.8239984854802669\n",
      "F1 score: 0.5501513533812535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "classifier = LogisticRegression(penalty=l_penalty)\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracies.append(classifier.score(X_test, y_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "print(\"Logistic regression:\")\n",
    "print(\"Accuracy:\", sum(accuracies)/len(accuracies))\n",
    "print(\"F1 score:\", sum(f1_scores)/len(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for finding the optimal C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_Cs = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    parameters = {'C':[0.1, 1, 10, 100, 1000]}\n",
    "    log_reg = LogisticRegression(penalty=l_penalty)\n",
    "    clf = GridSearchCV(log_reg, parameters, scoring='f1_macro')\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_Cs.append(clf.best_params_['C'])\n",
    "\n",
    "print(\"Logistic regression grid search - C parameter:\")\n",
    "print(\"The best Cs for each k-fold: \")\n",
    "print(best_Cs)\n",
    "print(\"Median:\")\n",
    "median_best_C = sorted(best_Cs)[int(len(best_Cs)/2)]\n",
    "print(median_best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty=l_penalty, C=median_best_C)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true, y_pred = y_test, log_reg.predict(X_test)\n",
    "print(\"Logistic regression (l=\" + l_penalty + \", C=\" + str(median_best_C) + \")\")\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracies.append(classifier.score(X_test, y_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "print(\"Multinomial Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", sum(accuracies)/len(accuracies))\n",
    "print(\"F1 score:\", sum(f1_scores)/len(f1_scores))\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "classifier = BernoulliNB()\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracies.append(classifier.score(X_test, y_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "print(\"Bernoulli Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", sum(accuracies)/len(accuracies))\n",
    "print(\"F1 score:\", sum(f1_scores)/len(f1_scores))\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# clf = LinearSVC(penalty=l_penalty)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "classifier = LinearSVC(penalty=l_penalty, dual=False)\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracies.append(classifier.score(X_test, y_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"Accuracy:\", sum(accuracies)/len(accuracies))\n",
    "print(\"F1 score:\", sum(f1_scores)/len(f1_scores))\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_Cs = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    parameters = {'C':[0.01, 0.1, 1, 10, 100]}\n",
    "    svm = LinearSVC(penalty=l_penalty)\n",
    "    clf = GridSearchCV(svm, parameters, scoring='f1_macro')\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_Cs.append(clf.best_params_['C'])\n",
    "\n",
    "    \n",
    "print(\"SVM grid search - C parameter:\")\n",
    "print(\"The best Cs for each k-fold: \")\n",
    "print(best_Cs)\n",
    "print(\"Median of those:\")\n",
    "median_best_C = sorted(best_Cs)[int(len(best_Cs)/2)]\n",
    "print(median_best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC(penalty=l_penalty, C=median_best_C, dual=False)\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracies.append(classifier.score(X_test, y_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\"Support Vector Machine, l=\" + str(l_penalty) + \", C=\" + str(median_best_C))\n",
    "print(\"Accuracy:\", sum(accuracies)/len(accuracies))\n",
    "print(\"F1 score:\", sum(f1_scores)/len(f1_scores))\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = time()\n",
    "print(t_end - t_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
